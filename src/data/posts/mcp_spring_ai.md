---
#preview
title: 'Spring AI + MCP: Fundamentos y Aplicaciones Pr谩cticas para Desarrolladores'
date: '2025-11-20'
image: "/img/blog/2.png"
categories:
    - Inteligencia Artificial
    - Backend
tags:
    - Java
    - Spring AI
    - MCP
    - LLMs
    - Arquitectura
author: Geovanny Mendoza
short: C贸mo integrar Model Context Protocol y Spring AI para construir aplicaciones de IA aumentada con datos reales, herramientas externas y capacidades personalizadas.
---

# Spring AI + MCP: Fundamentos y Aplicaciones Pr谩cticas para Desarrolladores

## Introducci贸n: El Protocolo de Contexto de Modelo (MCP)

En el universo en constante evoluci贸n de la inteligencia artificial, los Modelos de Lenguaje Grande (LLMs) han revolucionado c贸mo interactuamos con la tecnolog铆a. Sin embargo, estos modelos tienen limitaciones inherentes: est谩n entrenados con datos hasta cierto punto en el tiempo y no pueden acceder a informaci贸n espec铆fica o propietaria sin ayuda. Es aqu铆 donde entra el Protocolo de Contexto de Modelo (MCP).

El MCP es un est谩ndar emergente que permite a los desarrolladores aumentar las capacidades de los LLMs con contexto personalizado y funcionalidades adicionales. Imag铆nelo como un "puente" que conecta los modelos de lenguaje con fuentes de datos y capacidades externas. A diferencia de las APIs tradicionales que conectan servicios con clientes, los MCP est谩n dise帽ados espec铆ficamente para potenciar los LLMs, permiti茅ndoles acceder a informaci贸n en tiempo real o ejecutar acciones que normalmente estar铆an fuera de su alcance.

## 驴Por qu茅 necesitamos MCP? Limitaciones de los LLMs

Para entender la importancia del MCP, primero debemos comprender las limitaciones de los LLMs:

1. **Conocimiento congelado**: Los LLMs solo conocen informaci贸n hasta su fecha de corte de entrenamiento. Cualquier evento o dato posterior es desconocido para ellos.
2. **Sin acceso a datos propietarios**: No tienen acceso natural a informaci贸n espec铆fica de su empresa, documentos internos o bases de datos propietarias.
3. **Incapacidad para ejecutar acciones**: No pueden interactuar directamente con sistemas externos como APIs, bases de datos o servicios web.
4. **Sin acceso a informaci贸n en tiempo real**: No pueden acceder a informaci贸n actualizada sobre mercados financieros, clima, noticias recientes, etc.

Un ejemplo pr谩ctico: si pregunta a un LLM est谩ndar "驴Cu谩l es el estado actual de nuestro servidor de producci贸n?" o "驴Cu谩l fue el 煤ltimo correo electr贸nico de nuestro cliente principal?", no podr谩 responder con precisi贸n porque carece de acceso a sus sistemas.

## Spring AI: El puente hacia el futuro de las aplicaciones IA

Spring AI es un proyecto de Spring que facilita la integraci贸n de capacidades de IA en aplicaciones Java. Ofrece una interfaz unificada para trabajar con varios proveedores de LLMs (OpenAI, Anthropic, Google Gemini, etc.) y simplifica significativamente la implementaci贸n de clientes y servidores MCP.

Las ventajas principales de utilizar Spring AI incluyen:

- **Abstracci贸n del proveedor**: Escriba c贸digo una vez y c谩mbielo entre diferentes proveedores de LLMs sin modificaciones.
- **Integraci贸n nativa con el ecosistema Spring**: Aproveche todas las capacidades del ecosistema Spring que ya conoce.
- **Soporte completo para MCP**: Implementaci贸n simplificada tanto para clientes como servidores MCP.

## Configurando un Cliente MCP con Spring Boot

Vamos a ver c贸mo configurar un cliente MCP b谩sico utilizando Spring Boot. Este cliente se conectar谩 a un servidor MCP y utilizar谩 sus capacidades para mejorar las respuestas de un LLM.

### Paso 1: Configuraci贸n del proyecto

Primero, cree un proyecto Spring Boot con las dependencias necesarias:

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-mcp-client-spring-boot-starter</artifactId>
    </dependency>
</dependencies>
```

### Paso 2: Configuraci贸n del cliente MCP

Configure su aplicaci贸n en el archivo `application.yml`:

```yaml
spring:
  application:
    name: mcp-client-example
  
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
    
    mcp:
      client:
        name: example-mcp-client
        version: 0.0.1
        tool-callbacks-enabled: true
        streamable-http:
          connections:
            companyData:
              url: https://mcp.example-geovannycode.com/mcp
            marketData:
              url: https://market-data-mcp.example.com/mcp
```

Este ejemplo configura un cliente MCP que se conecta a dos servidores MCP diferentes: uno para datos de la empresa y otro para datos de mercado.

## Tipos de Transporte para Servidores MCP

Spring AI soporta tres tipos principales de transporte para servidores MCP:

1. **Streamable HTTP**: El enfoque preferido para servidores MCP remotos. Utiliza HTTP para la comunicaci贸n y admite streaming de respuestas.
2. **SSE (Server-Sent Events)**: Utiliza eventos enviados por el servidor para comunicaci贸n unidireccional desde el servidor al cliente.
3. **STDIO (Standard Input/Output)**: Ideal para servidores MCP locales que se ejecutan en el mismo sistema.

La elecci贸n del transporte depende de su caso de uso espec铆fico y la ubicaci贸n del servidor MCP.

### Configuraci贸n de diferentes transportes:

Para STDIO (servidores locales):
```yaml
spring:
  ai:
    mcp:
      client:
        stdio:
          connections:
            localTool:
              command: ["python", "/path/to/local_mcp_server.py"]
```

Para SSE:
```yaml
spring:
  ai:
    mcp:
      client:
        sse:
          connections:
            sseServer:
              url: https://sse-mcp-server.example.com/mcp
```

## Integrando OpenAI con Servidores MCP

Una vez configurado el cliente MCP, necesitamos integrarlo con un LLM. Vamos a utilizar OpenAI como ejemplo, pero el proceso es similar para otros proveedores como Anthropic o Google Gemini.

```java
@RestController
public class ChatController {
    
    private final Logger logger = LoggerFactory.getLogger(ChatController.class);
    private final ChatClient chatClient;
    
    public ChatController(ChatClient.Builder builder, 
                          ToolCallbackProvider toolCallbackProvider) {
        
        // Listar todas las herramientas disponibles
        Arrays.stream(toolCallbackProvider.getToolCallbacks())
              .forEach(tool -> 
                  logger.info("Tool callback found: {}", 
                      tool.getToolDefinition().getName()));
        
        // Configurar el cliente de chat con las herramientas MCP
        this.chatClient = builder
            .defaultToolCallbacks(toolCallbackProvider.getToolCallbacks())
            .build();
    }
    
    @GetMapping("/chat")
    public String chat(@RequestParam String message) {
        return chatClient.prompt(message).content().text();
    }
}
```

Este controlador configura un `ChatClient` con todas las herramientas disponibles del proveedor de callbacks de herramientas, y expone un endpoint `/chat` que acepta un mensaje y devuelve la respuesta del LLM aumentada con las capacidades de los servidores MCP.

## Implementaciones Posibles en Entornos Reales

### Caso 1: Sistema Financiero con Datos de Mercado en Tiempo Real

Imaginemos un banco que quiere proporcionar an谩lisis financiero personalizado a sus clientes. Mediante un cliente MCP, pueden conectar su LLM a:

1. Un servidor MCP de datos de mercado en tiempo real
2. Un servidor MCP con el historial financiero del cliente
3. Un servidor MCP con recomendaciones de productos financieros

Cuando un cliente pregunta: **驴Deber铆a invertir en acciones tecnol贸gicas considerando mi cartera actual?**, el LLM puede:

- Obtener los datos de mercado m谩s recientes
- Analizar la cartera actual del cliente
- Considerar su perfil de riesgo hist贸rico
- Proporcionar recomendaciones personalizadas basadas en productos disponibles

Todo esto sin que el LLM tenga acceso directo a informaci贸n sensible del cliente o datos de mercado propietarios.

### Caso 2: Sistema de Soporte T茅cnico Corporativo

Una empresa tecnol贸gica podr铆a implementar un asistente de soporte t茅cnico que:

1. Accede a la documentaci贸n interna mediante un servidor MCP
2. Consulta el estado actual de los sistemas a trav茅s de otro servidor MCP
3. Puede abrir tickets de soporte mediante un tercer servidor MCP

Cuando un empleado pregunta: **驴Por qu茅 no puedo acceder a la base de datos de clientes?**, el asistente podr铆a:

- Verificar el estado actual de la base de datos
- Revisar los logs de acceso del usuario
- Consultar problemas conocidos en la documentaci贸n interna
- Generar un ticket de soporte si es necesario

### Caso 3: Asistente M茅dico Inteligente

Un hospital podr铆a implementar un asistente para m茅dicos que:

1. Se conecta a la base de datos de historiales m茅dicos mediante un servidor MCP
2. Accede a las 煤ltimas investigaciones m茅dicas a trav茅s de otro servidor MCP
3. Puede ayudar a programar ex谩menes mediante un tercer servidor MCP

Cuando un m茅dico pregunta: **驴Qu茅 tratamiento recomiendas para este paciente con hipertensi贸n y diabetes?**, el asistente puede:

- Revisar el historial m茅dico completo del paciente
- Considerar las 煤ltimas investigaciones sobre tratamientos combinados
- Sugerir opciones basadas en los medicamentos disponibles en la farmacia del hospital
- Programar los ex谩menes de seguimiento necesarios

## Implementando un Cliente MCP de Extremo a Extremo

A continuaci贸n exploraremos c贸mo construir un cliente MCP totalmente funcional aplicado a un escenario t铆pico dentro de un sistema de gesti贸n de recursos humanos:

```java
@SpringBootApplication
public class HRAssistantApplication {

    public static void main(String[] args) {
        SpringApplication.run(HRAssistantApplication.class, args);
    }
    
    @RestController
    @RequestMapping("/hr-assistant")
    public class HRAssistantController {
        
        private final ChatClient chatClient;
        
        public HRAssistantController(ChatClient.Builder builder, 
                              ToolCallbackProvider toolProvider) {
            
            // Configurar el cliente de chat con un mensaje de sistema por defecto
            this.chatClient = builder
                .defaultToolCallbacks(toolProvider.getToolCallbacks())
                .defaultSystemMessage("Eres un asistente de RRHH que ayuda a los " +
                    "empleados con consultas relacionadas con pol铆ticas, " +
                    "beneficios y procedimientos de la empresa.")
                .build();
        }
        
        @PostMapping("/query")
        public ResponseEntity<Map<String, String>> handleQuery(
                @RequestBody Map<String, String> request) {
            
            String userQuery = request.get("query");
            String employeeId = request.get("employeeId");
            
            // Crear un mensaje con metadatos para el contexto
            UserMessage userMessage = new UserMessage(userQuery, 
                Map.of("employeeId", employeeId));
            
            // Obtener respuesta del LLM aumentado con herramientas MCP
            Prompt prompt = new Prompt(userMessage);
            Generation response = chatClient.generate(prompt);
            
            Map<String, String> responseBody = new HashMap<>();
            responseBody.put("response", response.getText());
            
            return ResponseEntity.ok(responseBody);
        }
    }
}
```

La configuraci贸n YAML correspondiente:

```yaml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
    
    mcp:
      client:
        name: hr-assistant-client
        version: 1.0.0
        tool-callbacks-enabled: true
        streamable-http:
          connections:
            employeeData:
              url: https://hr-data.geovannycode.internal/mcp
            companyPolicies:
              url: https://policies.geovannycode.internal/mcp
            benefitsSystem:
              url: https://benefits.geovannycode.internal/mcp
            ticketingSystem:
              url: https://tickets.geovannycode.internal/mcp
```

Este ejemplo implementa un asistente de recursos humanos que puede acceder a:

1. Datos de los empleados
2. Pol铆ticas de la empresa
3. Sistema de beneficios
4. Sistema de tickets para problemas de RRHH

## Ventajas de Utilizar Clientes MCP

Los clientes MCP ofrecen numerosas ventajas para aplicaciones modernas de IA:

1. **Independencia del proveedor**: Puede cambiar entre diferentes LLMs sin modificar su c贸digo o sus integraciones.
2. **Acceso a datos privados sin exposici贸n**: Los datos sensibles permanecen dentro de sus sistemas, solo se comparten los resultados relevantes.
3. **Informaci贸n siempre actualizada**: Acceda a informaci贸n en tiempo real sin necesidad de reentrenar modelos.
4. **Extensibilidad**: Agregue nuevas capacidades simplemente conectando nuevos servidores MCP.
5. **Reducci贸n de hallucinations**: Al proporcionar contexto preciso y actualizado, reduce significativamente las respuestas incorrectas o "alucinaciones" de los LLMs.
6. **Composabilidad**: Combine m煤ltiples servidores MCP para crear soluciones complejas y potentes.

## Consideraciones de Seguridad

Al implementar clientes MCP, debe considerar:

1. **Autenticaci贸n y autorizaci贸n**: Asegure sus servidores MCP con autenticaci贸n adecuada, como Spring Security.
2. **Control de acceso**: Limite qu茅 herramientas est谩n disponibles para diferentes usuarios o contextos.
3. **Validaci贸n de datos**: Verifique la entrada y salida de datos para evitar vulnerabilidades.
4. **Auditor铆a**: Implemente registros de auditor铆a para rastrear el uso de herramientas MCP.

```java
// Ejemplo de implementaci贸n de seguridad para un cliente MCP
@Configuration
@EnableWebSecurity
public class MCPSecurityConfig {

    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http
            .authorizeHttpRequests((authz) -> authz
                .requestMatchers("/admin/**").hasRole("ADMIN")
                .requestMatchers("/hr-assistant/**").hasRole("HR")
                .anyRequest().authenticated()
            )
            .oauth2ResourceServer(OAuth2ResourceServerConfigurer::jwt);
        return http.build();
    }
}
```

## Escalando su Implementaci贸n MCP

A medida que su aplicaci贸n crece, puede escalar su implementaci贸n MCP:

1. **M煤ltiples instancias**: Ejecute m煤ltiples instancias de sus servidores MCP para manejar cargas mayores.
2. **Cach茅**: Implemente cach茅 para respuestas comunes para reducir la carga en sus servidores MCP.
3. **Monitoreo**: Utilice Spring Actuator para monitorear el rendimiento de sus clientes y servidores MCP.
4. **Orquestaci贸n**: Utilice herramientas como Kubernetes para orquestar sus servidores MCP.


---

##  Proyecto de Ejemplo: MCP Client para Spring AI

Si desea profundizar a煤n m谩s y ver una implementaci贸n funcional, puede consultar el proyecto de ejemplo que acompa帽a este art铆culo.  
All铆 encontrar谩 un cliente MCP completo construido con Spring Boot, patrones recomendados y ejemplos listos para ejecutar.

 **Repositorio GitHub:**  
https://github.com/geovannymcode/mcp-client-example

Este proyecto incluye:

- Configuraci贸n base para Spring AI y clientes MCP  
- Ejemplos de transporte (HTTP, SSE, STDIO)  
- Integraci贸n con herramientas MCP  
- Buenas pr谩cticas de estructura y organizaci贸n del c贸digo  
- Ejemplo de endpoints para probar interacciones reales con LLMs  

Ideal para usar como plantilla en sus propios proyectos o como gu铆a de referencia para entender la arquitectura completa.

---

## Conclusi贸n: El Futuro es Aumentado

El Protocolo de Contexto de Modelo representa un avance significativo en c贸mo integramos los LLMs en aplicaciones empresariales. Al proporcionar un mecanismo est谩ndar para aumentar las capacidades de estos modelos, MCP permite crear aplicaciones m谩s inteligentes, precisas y 煤tiles.

Spring AI simplifica enormemente este proceso, permitiendo a los desarrolladores de Java aprovechar estas capacidades con un m铆nimo esfuerzo. Ya sea que est茅 construyendo un asistente interno para empleados, un sistema de an谩lisis financiero o una aplicaci贸n de atenci贸n m茅dica, los clientes MCP le permiten combinar lo mejor de los LLMs con sus datos y sistemas propietarios.

A medida que el ecosistema MCP contin煤a madurando, podemos esperar ver m谩s herramientas, integraciones y casos de uso que empujen los l铆mites de lo que es posible con la IA aumentada.

驴Listo para comenzar? Configure su primer cliente MCP hoy y experimente el poder de la IA contextualmente consciente en sus aplicaciones.

---

## Referencias y Recursos

1. **Anthropic - Model Context Protocol**  
   Documentaci贸n oficial del protocolo MCP  
   https://www.anthropic.com/news/model-context-protocol
2. **Spring AI - Documentation**  
   Documentaci贸n oficial de Spring AI  
   https://docs.spring.io/spring-ai/reference/
3. **OpenAI API Reference**  
   Documentaci贸n de la API de OpenAI  
   https://platform.openai.com/docs/api-reference
4. **Spring Boot Documentation**  
   Documentaci贸n oficial de Spring Boot  
   https://spring.io/projects/spring-boot
5. **Spring Security**  
   Gu铆a de implementaci贸n de seguridad en Spring  
   https://spring.io/projects/spring-security